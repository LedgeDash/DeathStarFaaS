RegisterUserWithId
additional input: `int64_t user_id`

In RegisterUser, a `int64_t   user_id` is generated based on the `_machine_id` of
the machine on which the microservice runs, a counter number and the current
time stamp of the registration request
(`int64_t timestamp = duration_cast<milliseconds>(system_clock::now()...)`).
This seems to be a manual implementation of UUID Version 1 (`uuid.uuid1()` function
in Python's uuid package).

## Uniqueness problem
The social network application wants global uniqueness for all user IDs. There are
multiple processes for registering user accounts. How to guarantee uniqueness?

A centralized sequencer could work.

UUID could also work, but it relies on getting the current timestamp. There is
a chance that 2 threads on the same machine gets the timestamp at the same time.
In the DeathStar implementation, they take a lock before `system_clock::now()`.
But how to do this in Cloudflare Workers where each `RegisterUser` function runs
in its own Isolate and there is global coordinator for creating function instances
so that they can all share a lock? Cloudflare could provide their own uuid
implementation where node ID is changed from the machine's MAC address to an
Isolate's ID. Then how many more packages do they need to re-implement?

This is not a problem in AWS Lambda, because functions run in VMs. As long as
each VM gets a unique node name, UUIDs won't have duplicates.

Or use UUID4 and rely on randomness.

# OpenFaaS
`sys.exit('error msg')` will return result with `Server returned unexpected
status code: 500 - exit status 1`, whereas `return('message')` will return
status code 200.


I can just return a dict and OpenFaaS runtime will convert that into a string:
```
return {"status": "success", "user_id": found['user_id']}
sys.exit({"status": "SomeError", "message": error_message})
```
**actually, I can't do this. Because this won't return a json string. fields will be
enclosed in single quotes... which causes `json.loads()` to fail.**
On the client side then, I can convert the string into a dictionary via `json.loads()`

# MongoDB

Access directly on the AKS cluster: `kubectl exec -it mongo-0 -- sh`. This
gives you a shell into the pod named `mongo-0`which is the primary node of
MongoDB.

To access the database for user account:

```bash
use users # switch to db `users`
db.getCollectionInfos()
db.users.find({}) # perform a query on the `users` collection and find everything
```

To clear all documents in a collection:
```bash
db.social_graph.remove({})
```

```
res = users.insert_one(new_user_doc)
print(new_user_doc)
```
`users.insert_one()` actually returns the new MongoDB document in
`new_user_doc`. In practice, this means that after `insert_one()`,
`new_user_doc` now also has a field `_id:ObjectId(..)`.

To use `from bson.json_util import dumps, loads`, we need to install `pymongo`.
In the case of OpenFaaS functions, this means adding `pymongo` into the
`requirements.txt` file.

# Data format

Fields don't include the MongoDB default `_id` field unless we manually create it.

Python and BSON data structure mapping: 

### MongoDB for users:

db: users

collection: users

fields:
1. `username`: string
2. `first_name`: string
3. `last_name`: string
4. `password`: hex string of hash
5. `user_id`: hex string of UUID4
6. `salt`: random string generated by secrets

See `register-user/handler.py` for details

### MongoDB for social graph

db: social_graph

collection: social_graph

fields:
1. `user_id`
2. `followers`: list (BSON array)
3. `followees`: list

# Mappings

## List of NGINX Routes

1. /api/user/register
2. /api/user/follow
3. /api/user/unfollow
4. /api/user/login
5. /api/post/compose
6. /api/user-timeline/read
7. /api/home-timeline/read
8. /api/user/get_follower
9. /api/user/get_followee
10. /
11. /wrk2-api/user-timeline/read
12. /wrk2-api/post/compose
13. /wrk2-api/user/register
14. /wrk2-api/user/follow
15. /wrk2-api/user/unfollow



Microservice types: `https://github.com/delimitrou/DeathStarBench/blob/master/socialNetwork/gen-cpp/social_network_types.h`

## /api/user/register

NGINX request URL: `/api/user/register`
LUA:
1. `api/user/register.lua`:`RegisterUser()`
2. `gen-lua/social_network_UserServer.lua`:`UserServiceClient:RegisterUser()`
Container Service: `user-service` 

NGINX request URL: `/api/post/compose`
LUA:
`api/post/compose.lua`:`ComposePost()`

user_id

username

req_id

`post`:
1. post.media_ids
2. post.media_types
3. post.post_type
4. post.text

creates 4 threads each calls:
1. `api/post/compose.lua`:`_UploadMedia(req_id, post)`
    1. `social_network_MediaService.lua`:`UploadMedia(req_id, post.media_types, post.media_ids)`
        1. `src/MediaService/MediaHandler.h`:`UploadMedia(req_id, vector<string> media_types, vector<int64_t>media_ids)`:
            compose_post_client->UploadMedia(req_id, media)
            1. `src/ComposePostService/ComposePostHandler.h`:UploadMedia(req_id, vector<Media>)
2. `api/post/compose.lua`:`_UploadUserId(req_id, user_id, username)`
    1. social_network_UserService:UploadCreatorWithUserId(req_id, user_id, username)
        1. `src/UserService/UserHandler.h`:`UploadCreatorWithUserId(req_id, user_id, username)
            compose_post_client->UploadCreator(req_id, creator)
            1. `src/ComposePostService/ComposePostHandler.h`:UploadCreator(req_id, vector<Media>)
3. `api/post/compose.lua`:`_UploadText(req_id, post)`
    1. social_network_TextService:UploadText(req_id, post.text)
        1. `src/TextService/TextHandler.h`:`UploadText(req_id, string text)`
            regex match on the text to get `vector<string> user_mentions` and `vector<string> urls`
            url_client->UploadUrls(return_urls, req_id, urls)
            user_mention_client->UploadUserMentions(req_id, user_mentions)
            compose_post_client->UploadText(req_id, updated_text)
            1. `src/UrlShortenService/UrlShortenHandler.h`:`UploadUrls(req_id, vector<string> urls)`:
                1. write to Mongo db: `url-shorten`, collection: `url-shorten` in bulk
                2. compose_post_client->UploadUrls(req_id, vector<Url> target_urls)
                    1. `src/ComposePostService/ComposePostHandler.h`:`UploadUrls(req_id, urls)`
            2. `src/UserMentionService/UserMentionHandler.h`:`UploadUserMentions(req_id, vector<string> usernames)`
                1. construct a vector<UserMention> user_mentions by querying memcached and mongodb
                2. compose_post_client->UploadUserMentions(req_id, user_mentions)
                    1. `src/ComposePostService/ComposePostHandler.h`:UploadUserMentions(req_id, vector<UserMention>)
4. api/post/compose.lua:_UploadUniqueId(req_id, post)
    1. social_network_UniqueIdService: UploadUniqueId(req_id, tonumber(post.type))
        1. `src/UniqueIdService/UniqueIdHandler.h`:`UploadUniqueId(req_id, PostType::type post_type)`
            compose_post_client->UploadUniqueId(req_id, post_id, post_type)
            1. src/ComposePostService/ComposePostHandler.h:UploadUniqueId(req_id, post_id, post_type)



## compose-post-frontend
`{"post_type":0,"text":"asdf","media_id":"lofotenIslandsNorway-1fd5f0c1e92147f3baf6cf7e630f763d","media_type":"jpg"}`
`{"post_type":0,"text":"asdf"}`

There's a  `post_type`. 

It's defined in `socialNetwork/social_network.thrift`, and `socialNetwork/gen-cpp/social_network_types.h`.

In NGINX `compose.lua`, it gets the `user_id` and `username` by :

```lua
jwt:verify(ngx.shared.config:get("secret"), ngx.var.cookie_login_token)
```

So I digged into login to see how login (or session cookies) is handled

the `Login()` function in `src/UserService/UserHandler.h` returns:

```c++
      jwt::jwt_object obj{
          algorithm("HS256"),
          secret(_secret),
          payload({
              {"user_id", user_id_str},
              {"username", username},
              {"timestamp", timestamp_str},
              {"ttl", "3600"}
          })
      };
      _return = obj.signature();
```

The JWT library is from: https://github.com/arun11299/cpp-jwt

Here's an intro to JWT: https://jwt.io/introduction/

The actual check at login is a simple hashing of password plus the store salt value.

The recipient of this token is `api/user/login.lua`:

```lua
local status, ret = pcall(client.Login, client, req_id,
      args.username, args.password, carrier)
      
if not status then
    ngx.status = ngx.HTTP_INTERNAL_SERVER_ERROR
    ...
else
	ngx.header.content_type = "text/plain"
    ngx.header["Set-Cookie"] = "login_token=" .. ret .. "; Path=/; Expires="
        .. ngx.cookie_time(ngx.time() + ngx.shared.config:get("cookie_ttl"))
    
    ngx.redirect("../../main.html?username=" .. args.username)
    ngx.exit(ngx.HTTP_OK)
end
```

`ngx.cookie_time()`: https://github.com/openresty/lua-nginx-module#ngxcookie_time

It's not clear what `ngx.header["Set-Cookie"]` does. Specifically, does this return a HTTP response back to the client browser with that header, in which case **the client browser acquires the login token?**

OK, I confirmed with my local DeathStar deployment that the request to login sends a HTTP request with the following header:

```
Cookie: username-localhost-8888="2|1:0|10:1596559736|23:username-localhost-8888|44:M2FjMzc4M2MxYjRkNDBmNDlhMDM1NjdjMWU4ZTBhOTM=|475c9355ae9ee757b35f35d1405ac3feb6da7a54429a2052cb093308041dbf12"
```

The actual form data is:

```
{"username":"dhl","password":"19922008","login":"Login"}
```

The payload is sent as query string:

```
username=dhl&password=19922008&login=Login
```

The response HTTP package has the following header:

```
Set-Cookie: login_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0aW1lc3RhbXAiOiIxNTk4NTgwNzc0IiwidHRsIjoiMzYwMCIsInVzZXJfaWQiOiI0MjQyNzIzMTM2NDIzMzk5NDI0IiwidXNlcm5hbWUiOiJkaGwifQ.3OiDx4tNumxm0wZwUxtnj_pV0ZwSczVSKWrQZiLutLE; Path=/; Expires=Sat, 29-Aug-20 02:12:54 GMT
```

This login_token is sent in HTTP headers to other APIs. For example in the HTTP request to `get_followees`:

```
Cookie: username-localhost-8888="2|1:0|10:1596559736|23:username-localhost-8888|44:M2FjMzc4M2MxYjRkNDBmNDlhMDM1NjdjMWU4ZTBhOTM=|475c9355ae9ee757b35f35d1405ac3feb6da7a54429a2052cb093308041dbf12"; login_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0aW1lc3RhbXAiOiIxNTk4NTgwNzc0IiwidHRsIjoiMzYwMCIsInVzZXJfaWQiOiI0MjQyNzIzMTM2NDIzMzk5NDI0IiwidXNlcm5hbWUiOiJkaGwifQ.3OiDx4tNumxm0wZwUxtnj_pV0ZwSczVSKWrQZiLutLE
```

NGINX Lua scripts explicitly check for the the login token:

`api/user/get_follower.lua` and `api/user/get_followee.lua`:

```
 if (_StrIsEmpty(ngx.var.cookie_login_token)) then
    ngx.status = ngx.HTTP_UNAUTHORIZED
    ngx.exit(ngx.HTTP_OK)
  end

  local login_obj = jwt:verify(ngx.shared.config:get("secret"), ngx.var.cookie_login_token)
  if not login_obj["verified"] then
    ngx.status = ngx.HTTP_UNAUTHORIZED
    ngx.say(login_obj.reason);
    ngx.exit(ngx.HTTP_OK)
  end

  local timestamp = tonumber(login_obj["payload"]["timestamp"])
  local ttl = tonumber(login_obj["payload"]["ttl"])
  local user_id = tonumber(login_obj["payload"]["user_id"])

  if (timestamp + ttl < ngx.time()) then
    ngx.status = ngx.HTTP_UNAUTHORIZED
    ngx.header.content_type = "text/plain"
    ngx.say("Login token expired, please log in again")
    ngx.exit(ngx.HTTP_OK)
  else
```

Here's an example of what `jwt:verify()` returns: https://github.com/SkyLothar/lua-resty-jwt#sample-of-jwt_obj

### Synchronous vs Asynchronous

microservice calls in the original DeathStar are really synchronous. Even when they use async, they wait for it to finish. So from a client's perspective, it's synchronous. 



From a client perspective, e2e latency is the same. 



utilization-wise, if synchronous we should just let compose-post-frontend call compose-and-upload when the other 4 functions are done so that we don't hold up any of the other functions. If async, then there's no waiting at all. utilization will be much better.

Throughput wise, is synchronous waiting will hurt throughput. But even if it's async, the e2e throughput is still the slowest function is it not? **NO! because we can then scale those functions independently!!**

The difference between serverless and microservices in this case is that in microservices, you still need to manage your own pool of services (like a pool of UserServices pods, and you need to call pop and push in your code), but in serverless, you don't. You just call the function and the pushing, popping, resizing are done transparently for you.

A question is resizing pools.

Adaptive Deployment and Resizing for Serverless Applications

# Difference between FaaS and microservices

## Greater number of database connections?

each function instance keeps a pool of connections

### Microservice applications need to manage pools of each service themselves?

Does K8S solves this for them?